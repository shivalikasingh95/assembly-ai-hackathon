import replicate
import os
from diffusers import StableDiffusionPipeline
import torch
from PIL.Image import Image
from PIL import PngImagePlugin
from typing import Dict
from io import BytesIO
import base64
from .utils import upload_file_to_s3
import time

def generate_cover_art_replicate(config: Dict, model_params):
    """
    This function uses one of the Stable Diffusion models available via Replicate to generate the cover art for a music piece.
    Args:
        model_params (cover_art_input): stable diffusion model params that will be used to tweak model output for cover art generation 
        config (dict): Configuration to be used by the model for genration of cover art
    Returns:
        response (str): Link(s) to image output generated by the model hosted by Replicate
    """

    # load model
    model_name = config["replicate_model_name"]
    model = replicate.models.get(model_name)

    # load correct model version
    model_version = config["replicate_model_version"]
    version = model.versions.get(model_version)
    
    # define model parameters
    COVER_ART_PROMPT = model_params.text_prompt
    WIDTH = model_params.image_width
    HEIGHT = model_params.image_height
    STEP_COUNT = model_params.num_inference_steps
    GUIDANCE_SCALE = model_params.guidance_scale
    COVER_ART_COUNT = model_params.num_outputs

    # generate cover art images
    generated_cover_art = version.predict(prompt = COVER_ART_PROMPT,num_outputs=COVER_ART_COUNT, 
                            width=WIDTH, height=HEIGHT,num_inference_steps=STEP_COUNT, guidance_scale=GUIDANCE_SCALE)
    
    return generated_cover_art

def generate_cover_art_HF(config: dict, model_params):
    """
    This function uses a default/custom trained model for music cover art from Hugging Face Hub
    Args:
        model_params (cover_art_input): stable diffusion model params that will be used to tweak model output for cover art generation 
        config (dict): Configuration to be used by the model for genration of cover art
    Returns:
        response (str): Link(s) to image output generated by the model hosted on S3
    """

    device = "cuda" if torch.cuda.is_available() else "cpu"

    COVER_ART_PROMPT = model_params.text_prompt
    WIDTH = model_params.image_width
    HEIGHT = model_params.image_height
    STEP_COUNT = model_params.num_inference_steps
    GUIDANCE_SCALE = model_params.guidance_scale
    COVER_ART_COUNT = model_params.num_outputs

    if model_params.model_choice == "custom":
        ## load custom trained model using dreambooth
        model_name = config["hf_dreambooth_model_name"]
    else:
        ## else load default SD checkpoint of runwayml
        model_name = config["hf_default_model_name"]
    
    pipe = StableDiffusionPipeline.from_pretrained(model_name).to(device)

    images = pipe(COVER_ART_PROMPT, num_images_per_prompt=COVER_ART_COUNT, num_inference_steps=STEP_COUNT, 
                            guidance_scale=GUIDANCE_SCALE).images
    img_urls_list = []
    base64_list = []
    for idx,img in enumerate(images):
        timestamp = time.strftime("%m-%d_%H-%M-%S", time.localtime()) 
        img_path = os.path.join(config["cover_art_dir"], f"{timestamp}_{idx}.png")
        img.save(img_path)
        upload_file_to_s3(img_path, config['s3_bucket_name'])
        os.remove(img_path)
        s3_img_url = f"https://{config['s3_bucket_name']}.s3.{config['s3_bucket_region']}.amazonaws.com/{img_path}"
        img_urls_list.append(s3_img_url)

        if config["encode_base64"]:
             ## encode image to base64
            base64_img = encode_pil_to_base64(img)
            base64_list.append(base64_img)
    
    return img_urls_list, base64_list

def encode_pil_to_base64(pil_image):
    """
    This function is used to convert a PIL image to a Base64 encoded string
    Args:
        pil_image (PIL.Image.Image): PIL.Image.Image object 
    Returns:
        final_base64_str (str): given PIL image converted to a base64 encoded string
    """
    with BytesIO() as output_bytes:

        use_metadata = False
        metadata = PngImagePlugin.PngInfo()
        for key, value in pil_image.info.items():
            if isinstance(key, str) and isinstance(value, str):
                metadata.add_text(key, value)
                use_metadata = True

        pil_image.save(
            output_bytes, "PNG", pnginfo=(metadata if use_metadata else None)
        )
        bytes_data = output_bytes.getvalue()
    base64_str = str(base64.b64encode(bytes_data), "utf-8")
    final_base64_str = "data:image/png;base64," + base64_str
    return final_base64_str