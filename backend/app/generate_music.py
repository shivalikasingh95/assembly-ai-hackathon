import os
import sys
import time
import torch
from midi2audio import FluidSynth
from .utils import upload_file_to_s3
sys.path.append("../ml/")
from SymphonyNet.src.fairseq.gen_utils import (
    process_prime_midi, 
    gen_one, get_trk_ins_map, 
    get_note_seq, note_seq_to_midi_file, 
    music_dict
)
from fairseq.models import FairseqLanguageModel

def generate_music(config: dict, midi_file_contents=None, midi_file_path: str = None):
    """
    This function calls the SymphonyNet model & generates the output music corresponding to given input midi file.
    Args:
        config (dict): config dictionary for music generation task
        midi_file_path (str): path of input midi file for the model
    Returns:
        mp3_output_path (str): path of mp3 file generated corresponding to the note sequence predicted by the model
    """
    
    ## set up config for model
    MAX_POS_LEN = config["max_pos_len"]
    PI_LEVEL = config["pi_level"]
    IGNORE_META_LOSS = config["ignore_meta_loss"]
    RATIO = config["ratio"]
    BPE = config["bpe"]
    DATA_BIN = f"linear_{MAX_POS_LEN}_chord{BPE}_hardloss{IGNORE_META_LOSS}"
    CHECKPOINT_SUFFIX = f"{DATA_BIN}_PI{PI_LEVEL}"
    DATA_BIN_DIR = config["data_base_dir"] + f"model_spec/{DATA_BIN}/bin/"
    DATA_VOC_DIR = config["data_base_dir"] + f"model_spec/{DATA_BIN}/vocabs/"
    BPE_DIR = config["data_base_dir"] +'/bpe_res/'
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

    music_dict.load_vocabs_bpe(DATA_VOC_DIR, BPE_DIR if BPE == '_bpe' else None)
    
    ## Load SymphonyNet model using checkpoint file path
    custom_lm = FairseqLanguageModel.from_pretrained('.', 
        checkpoint_file=config['symphonynet_ckpt_path'], 
        data_name_or_path=DATA_BIN_DIR, 
        user_dir=config["fairseq_user_dir"]
    )
    
    ## put model in eval mode for prediction
    music_gen_model = custom_lm.models[0]
    if DEVICE == "cuda":
        music_gen_model.cuda()
    music_gen_model.eval()

    ## preprocess input midi file before feeding to model for prediction
    max_measure_cnt = config["prime_measure_count"]
    max_chord_measure_cnt = config["max_chord_measure_cnt"]
    prime, ins_label = process_prime_midi(midi_file_path, midi_file_contents, max_measure_cnt, max_chord_measure_cnt)
    
    ## generate note sequence output using SymphonyNet model
    while (True):
        try:
            generated, ins_logits = gen_one(music_gen_model, prime, MIN_LEN = 1024)
            break
        except Exception as e:
            ## if invalid excerpt generated then try again 
            print(e)
            continue
    trk_ins_map = get_trk_ins_map(generated, ins_logits)
    note_seq = get_note_seq(generated, trk_ins_map)
    
    ## generate midi file corresponding generated note sequence by model
    timestamp = time.strftime("%m-%d_%H-%M-%S", time.localtime()) 
    midi_output_path = config["midi_out_folder"] + f'output_prime{max_measure_cnt}_chord{max_chord_measure_cnt}_{timestamp}.mid'
    note_seq_to_midi_file(note_seq, midi_output_path)

    ## finally convert midi file generated by model to mp3
    mp3_output_path = config["mp3_out_folder"] + f'output_prime{max_measure_cnt}_chord{max_chord_measure_cnt}_{timestamp}.mp3'
    convert_midi_to_mp3(config["sound_font_file_path"], midi_output_path, mp3_output_path, config['sampling_rate'])

    ## upload mp3 file to s3
    # upload_file_to_s3(mp3_output_path, config['s3_bucket_name'])

    if config["delete_audio_files"]:
        ## delete local audio files after uploading to S3
        delete_local_audio_files(midi_output_path, mp3_output_path)

    return mp3_output_path


def convert_midi_to_mp3(sound_font_path: str, midi_file_path: str, mp3_file_path: str, sampling_rate: int):
    """
    This function helps to convert a given midi file to its corresponding mp3 file
    Args:
        sound_font_path (str): path to sound font file that will be used for midi to mp3 conversion
        midi_file_path (str): path of midi file that needs to be converted 
        mp3_file_path (str): path of mp3 file generated after conversion
        sampling_rate (int): sampling rate to be used for converting audio
    """
    fs = FluidSynth(sound_font_path,sample_rate=sampling_rate)
    fs.midi_to_audio(midi_file_path, mp3_file_path)

def delete_local_audio_files(midi_file_path: str, mp3_file_path: str):
    """
    This function helps to delete midi & mp3 files generated locally after upload to s3
    Args:
        midi_file_path (str): path of midi file that needs to be deleted
        mp3_file_path (str): path of mp3 file that needs to be deleted
    """

    os.remove(midi_file_path)
    os.remove(mp3_file_path)
